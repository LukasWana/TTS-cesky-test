"""
HiFi-GAN Vocoder wrapper pro XTTS-v2 TTS Engine
"""
import numpy as np
from typing import Optional
from pathlib import Path
import backend.config as config
import torch


class HiFiGANVocoder:
    """
    Wrapper pro HiFi-GAN vocoder s lazy-loading a per-request parametry
    """

    def __init__(self):
        self._model = None
        self._model_loaded = False
        self._available = False
        self._parallel_wavegan_available = False
        self._models_dir = Path(config.MODELS_DIR) / "hifigan"
        self._initialize()

    def _initialize(self):
        """Inicializuje HiFi-GAN vocoder pokud je dostupn√Ω"""
        if not config.ENABLE_HIFIGAN:
            self._available = False
            return

        try:
            from colorama import Fore, Style
            COLOR_OK = Fore.GREEN
            COLOR_WARN = Fore.YELLOW
            COLOR_INFO = Fore.CYAN
            COLOR_RESET = Style.RESET_ALL
        except ImportError:
            COLOR_OK = COLOR_WARN = COLOR_INFO = COLOR_RESET = ""

        try:
            # Zkus naƒç√≠st parallel-wavegan (nejbƒõ≈ænƒõj≈°√≠ implementace)
            try:
                from parallel_wavegan.utils import download_pretrained_model, load_model
                from parallel_wavegan.models import ParallelWaveGANGenerator
                self._parallel_wavegan_available = True
                self._available = True
                # Model se naƒçte a≈æ p≈ôi prvn√≠m pou≈æit√≠ (lazy loading)
                print(f"{COLOR_OK}‚úÖ parallel-wavegan je dostupn√Ω (lazy loading modelu){COLOR_RESET}")
            except ImportError:
                # Parallel-wavegan nen√≠ dostupn√Ω, zkus jin√© mo≈ænosti
                try:
                    # Zkus hifigan p≈ô√≠mo (pokud existuje)
                    import hifigan
                    self._available = True
                    print(f"{COLOR_OK}‚úÖ hifigan je dostupn√Ω{COLOR_RESET}")
                except ImportError:
                    self._available = False
                    print(f"{COLOR_WARN}‚ö†Ô∏è  HiFi-GAN nen√≠ dostupn√Ω: parallel-wavegan ani hifigan nejsou nainstalov√°ny{COLOR_RESET}")
        except Exception as e:
            self._available = False
            print(f"{COLOR_WARN}‚ö†Ô∏è  HiFi-GAN inicializace selhala: {e}{COLOR_RESET}")

    def _load_model(self) -> bool:
        """
        Naƒçte HiFi-GAN model (lazy loading)

        Returns:
            True pokud se model √∫spƒõ≈°nƒõ naƒçetl
        """
        if self._model_loaded:
            return self._model is not None

        if not self._available:
            return False

        try:
            if self._parallel_wavegan_available:
                # Zkus naj√≠t lok√°ln√≠ model v models/hifigan/
                model_path = self._models_dir
                config_path = model_path / "config.yaml"
                checkpoint_path = model_path / "checkpoint.pkl"
                checkpoint_pth_path = model_path / "checkpoint.pth"

                # Zkus nejd≈ô√≠v .pkl, pak .pth (kompatibilita s HuggingFace modely)
                if not checkpoint_path.exists() and checkpoint_pth_path.exists():
                    checkpoint_path = checkpoint_pth_path

                # Pokud lok√°ln√≠ model neexistuje, zkus fallback na HuggingFace cache
                if not config_path.exists() or not checkpoint_path.exists():
                    print("‚ö†Ô∏è  Lok√°ln√≠ HiFi-GAN model neexistuje v models/hifigan/, zkou≈°√≠m HuggingFace cache...")

                    # Zkus naj√≠t sta≈æen√Ω model v HuggingFace cache
                    hf_cache_dir = Path.home() / ".cache" / "huggingface" / "hub"
                    hf_model_dirs = [
                        "models--espnet--kan-bayashi_ljspeech_joint_finetune_conformer_fastspeech2_hifigan",
                        "models--espnet--kan-bayashi_ljspeech_hifigan",
                        "models--kan-bayashi--ljspeech_hifigan.v1"
                    ]

                    for model_dir_name in hf_model_dirs:
                        model_cache_path = hf_cache_dir / model_dir_name
                        if model_cache_path.exists():
                            # Najdi nejnovƒõj≈°√≠ snapshot
                            snapshots_dir = model_cache_path / "snapshots"
                            if snapshots_dir.exists():
                                snapshots = list(snapshots_dir.glob("*"))
                                if snapshots:
                                    latest_snapshot = max(snapshots, key=lambda x: x.stat().st_mtime)
                                    print(f"üì¶ Na≈°el HiFi-GAN model v HuggingFace cache: {model_dir_name}")

                                    # Najdi config a checkpoint v snapshotu
                                    exp_dirs = list(latest_snapshot.glob("exp/*hifigan*"))
                                    if exp_dirs:
                                        exp_dir = exp_dirs[0]
                                        hf_config_path = exp_dir / "config.yaml"
                                        hf_checkpoint_path = exp_dir / "train.total_count.ave_5best.pth"

                                        if hf_config_path.exists() and hf_checkpoint_path.exists():
                                            print("‚úÖ Pou≈æ√≠v√°m HiFi-GAN model z HuggingFace cache")
                                            config_path = hf_config_path
                                            checkpoint_path = hf_checkpoint_path
                                            break

                    # Pokud se st√°le nepoda≈ôilo naj√≠t model
                    if not config_path.exists() or not checkpoint_path.exists():
                        print("‚ö†Ô∏è  HiFi-GAN model nebyl nalezen ani v lok√°ln√≠m adres√°≈ôi ani v HuggingFace cache")
                        print("   HiFi-GAN refinement bude p≈ôeskoƒçen")
                        self._model_loaded = True  # Oznaƒç√≠me jako "zkou≈°eno", abychom nezkou≈°eli opakovanƒõ
                        return False

                # Naƒçten√≠ modelu z lok√°ln√≠ho checkpointu
                from parallel_wavegan.utils import load_model
                # P≈ôevod Path objekt≈Ø na stringy pro load_model
                self._model = load_model(str(checkpoint_path), str(config_path))
                self._model.remove_weight_norm()  # Odstranƒõn√≠ weight norm pro inference
                self._model.eval()
                if torch.cuda.is_available():
                    self._model = self._model.cuda()
                checkpoint_type = "lok√°ln√≠ho checkpointu (.pkl)" if checkpoint_path.suffix == ".pkl" else "HuggingFace cache (.pth)"
                print(f"‚úÖ HiFi-GAN model naƒçten z {checkpoint_type}")
                self._model_loaded = True
                return True
            else:
                # Jin√© implementace (hifigan-direct atd.) - zat√≠m neimplementov√°no
                print("‚ö†Ô∏è  Jin√© HiFi-GAN implementace zat√≠m nejsou podporov√°ny")
                self._model_loaded = True
                return False

        except Exception as e:
            print(f"‚ö†Ô∏è  Chyba p≈ôi naƒç√≠t√°n√≠ HiFi-GAN modelu: {e}")
            self._model_loaded = True
            return False

    @property
    def available(self) -> bool:
        """Vrac√≠ True pokud je HiFi-GAN dostupn√Ω"""
        return self._available

    def is_available(self) -> bool:
        """Vrac√≠ True pokud je HiFi-GAN dostupn√Ω a naƒçten√Ω"""
        if not self._available:
            return False
        return self._load_model()

    @property
    def mel_params(self) -> dict:
        """Vrac√≠ parametry mel-spectrogramu pro HiFi-GAN"""
        return {
            "n_mels": config.HIFIGAN_N_MELS,
            "n_fft": config.HIFIGAN_N_FFT,
            "hop_length": config.HIFIGAN_HOP_LENGTH,
            "win_length": config.HIFIGAN_WIN_LENGTH,
            "fmin": config.HIFIGAN_FMIN,
            "fmax": config.HIFIGAN_FMAX
        }

    def vocode(
        self,
        mel_log: np.ndarray,
        sample_rate: int,
        original_audio: Optional[np.ndarray] = None,
        refinement_intensity: Optional[float] = None,
        normalize_output: Optional[bool] = None,
        normalize_gain: Optional[float] = None
    ) -> Optional[np.ndarray]:
        """
        P≈ôev√°d√≠ mel-spectrogram zpƒõt na audio pomoc√≠ HiFi-GAN

        Args:
            mel_log: Log-mel spectrogram (numpy array, shape: [n_mels, time])
            sample_rate: Sample rate v√Ωstupn√≠ho audio
            original_audio: P≈Øvodn√≠ audio pro blending (voliteln√©)
            refinement_intensity: Intenzita refinementu (0.0-1.0, None = pou≈æ√≠t config v√Ωchoz√≠)
            normalize_output: Normalizovat v√Ωstup (None = pou≈æ√≠t config v√Ωchoz√≠)
            normalize_gain: Gain pro normalizaci (0.0-1.0, None = pou≈æ√≠t config v√Ωchoz√≠)

        Returns:
            Vygenerovan√© audio jako numpy array, nebo None pokud sel≈æe
        """
        if not self.is_available():
            return None

        # Pou≈æij per-request parametry nebo fallback na config v√Ωchoz√≠
        intensity = refinement_intensity if refinement_intensity is not None else config.HIFIGAN_REFINEMENT_INTENSITY
        do_normalize = normalize_output if normalize_output is not None else config.HIFIGAN_NORMALIZE_OUTPUT
        gain = normalize_gain if normalize_gain is not None else config.HIFIGAN_NORMALIZE_GAIN

        try:
            if self._parallel_wavegan_available and self._model is not None:
                # P≈ôevod mel_log na torch tensor
                # parallel-wavegan oƒçek√°v√° mel v line√°rn√≠m ≈°k√°lov√°n√≠, ne log
                # (ale to z√°vis√≠ na konkr√©tn√≠m modelu - nƒõkter√© modely oƒçek√°vaj√≠ log-mel)
                # Pro bezpeƒçnost zkus√≠me obƒõ varianty
                mel_tensor = torch.from_numpy(mel_log.astype(np.float32)).unsqueeze(0)
                if torch.cuda.is_available():
                    mel_tensor = mel_tensor.cuda()

                # Inference
                with torch.no_grad():
                    # Nƒõkter√© modely oƒçek√°vaj√≠ exponenci√°ln√≠ transformaci (pokud je mel_log skuteƒçnƒõ log)
                    # Zkus√≠me p≈ô√≠mo (pokud model oƒçek√°v√° log-mel)
                    try:
                        vocoded = self._model.inference(mel_tensor).squeeze().cpu().numpy()
                    except Exception:
                        # Pokud sel≈æe, zkus√≠me exponenci√°ln√≠ transformaci
                        mel_exp = np.exp(mel_log)
                        mel_tensor = torch.from_numpy(mel_exp.astype(np.float32)).unsqueeze(0)
                        if torch.cuda.is_available():
                            mel_tensor = mel_tensor.cuda()
                        vocoded = self._model.inference(mel_tensor).squeeze().cpu().numpy()

                # Resampling na target sample rate pokud je pot≈ôeba
                # (parallel-wavegan typicky generuje 22050 Hz, ale m≈Ø≈æeme m√≠t jin√Ω target)
                if sample_rate != 22050:
                    import librosa
                    vocoded = librosa.resample(vocoded, orig_sr=22050, target_sr=sample_rate)

                # Blending s original_audio pokud je zad√°n a intensity < 1.0
                if original_audio is not None and intensity < 1.0:
                    # Zajist√≠me stejnou d√©lku
                    min_len = min(len(vocoded), len(original_audio))
                    vocoded = vocoded[:min_len]
                    original_audio = original_audio[:min_len]
                    # Blend
                    vocoded = intensity * vocoded + (1.0 - intensity) * original_audio

                # Normalizace v√Ωstupu
                if do_normalize:
                    # Headroom ceiling - pouze ztlumit, nikdy nezesilovat (stejnƒõ jako fin√°ln√≠ headroom)
                    # POZOR: P≈Øvodn√≠ implementace zesilovala audio pokud peak < gain, co≈æ zp≈Øsobovalo p≈ôebuzen√≠!
                    # ≈òe≈°en√≠: pou≈æ√≠t headroom ceiling approach - pouze ztlumit pokud peak p≈ôes√°hl c√≠l
                    peak = np.max(np.abs(vocoded))
                    if peak > 0:
                        target_peak = gain  # gain je c√≠lov√Ω peak (nap≈ô. 0.95 = -0.45 dB)
                        # Pouze ztlumit pokud peak p≈ôes√°hl c√≠l, nikdy nezesilovat
                        if peak > target_peak:
                            vocoded = vocoded * (target_peak / peak)
                        # Pokud je peak < target_peak, nic nedƒõl√°me (nezesilujeme - to by zp≈Øsobilo p≈ôebuzen√≠)

                return vocoded
            else:
                print("‚ö†Ô∏è  HiFi-GAN model nen√≠ naƒçten")
                return None

        except Exception as e:
            print(f"‚ö†Ô∏è  HiFi-GAN vocoding selhal: {e}")
            import traceback
            traceback.print_exc()
            return None


# Singleton instance
_vocoder_instance: Optional[HiFiGANVocoder] = None


def get_hifigan_vocoder() -> HiFiGANVocoder:
    """
    Vrac√≠ singleton instanci HiFi-GAN vocoder

    Returns:
        HiFiGANVocoder instance
    """
    global _vocoder_instance
    if _vocoder_instance is None:
        _vocoder_instance = HiFiGANVocoder()
    return _vocoder_instance
